{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speed_up_QnA_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOAL9OPwwv68YrMHXke1VP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi9716/notebooks/blob/master/speed_up_QnA_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj-4m9jJ7NDa"
      },
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErrVV2Jy2Sc_",
        "outputId": "5d44d6a4-d3ba-4f27-8f09-71e941d1dcd7"
      },
      "source": [
        "# !pip install onnxruntime\n",
        "# !pip install --upgrade git+https://github.com/huggingface/transformers\n",
        "!pip install transformers onnxruntime onnx psutil \n",
        "!pip install onnxruntime-tools"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 3.8MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/f0/666d6e3ceaa276a54e728f9972732e058544cbb6a3e1a778a8d6f87132c1/onnxruntime-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 38.7MB/s \n",
            "\u001b[?25hCollecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (56.0.0)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, onnxruntime, onnx\n",
            "Successfully installed onnx-1.9.0 onnxruntime-1.7.0 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting onnxruntime-tools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/b0/db0e73356df0aaa8737e6f13c0dac499b5d904d3fa267c8ebf24515e8001/onnxruntime_tools-1.7.0-py3-none-any.whl (212kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime-tools) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnxruntime-tools) (1.19.5)\n",
            "Collecting py3nvml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/b3/cb30dd8cc1198ae3fdb5a320ca7986d7ca76e23d16415067eafebff8685f/py3nvml-0.2.6-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hCollecting coloredlogs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/a6/837dbf6eac344cb74f0ba86b79e8180855570af3e26bcb1ea5f650cf944c/coloredlogs-15.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (from onnxruntime-tools) (1.9.0)\n",
            "Collecting py-cpuinfo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from onnxruntime-tools) (5.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime-tools) (2.4.7)\n",
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Collecting humanfriendly>=9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx->onnxruntime-tools) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx->onnxruntime-tools) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnxruntime-tools) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx->onnxruntime-tools) (56.0.0)\n",
            "Building wheels for collected packages: py-cpuinfo\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=1608e1a26fb5def0e1a780d5b653ce552c58914a6bc156b32215f21282252c10\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built py-cpuinfo\n",
            "Installing collected packages: xmltodict, py3nvml, humanfriendly, coloredlogs, py-cpuinfo, onnxruntime-tools\n",
            "Successfully installed coloredlogs-15.0 humanfriendly-9.1 onnxruntime-tools-1.7.0 py-cpuinfo-8.0.0 py3nvml-0.2.6 xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHCJz1qTxJO"
      },
      "source": [
        "# !pip install transformers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSY_BBuQyP4x"
      },
      "source": [
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbQ0DLgF9v5h",
        "outputId": "9135b0f9-876a-4151-c0ce-4e03bbd01584"
      },
      "source": [
        "%%time\n",
        "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
        "import torch\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
        "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
        "inputs = tokenizer(question, text, return_tensors='pt')\n",
        "start_positions = torch.tensor([1])\n",
        "end_positions = torch.tensor([3])\n",
        "outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
        "loss = outputs.loss\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "answer_start = torch.argmax(\n",
        "        start_scores\n",
        "    )  # Get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[answer_start:answer_end]))\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Question: Who was Jim Henson?\n",
            "Answer: \n",
            "CPU times: user 2 s, sys: 116 ms, total: 2.11 s\n",
            "Wall time: 2.65 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2UT2qHnzZ6I",
        "outputId": "78453c62-4f10-4ea7-c85b-fb1dcd8affc7"
      },
      "source": [
        "%%time\n",
        "import json\n",
        "import requests\n",
        "API_TOKEN=\"BFOdJbLtxgBzhwYJaDuKJAVcnQmDwuMalejmAtedlXSZINgUBwkInjUoRqZhwjbTVPfUTMLYsCrhtoFsJnsluVjvxUlsvfKnqXrZbITHCNSxHDpWKQftiLjVPbIsjJoL\"\n",
        "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "API_URL = \"https://api-inference.huggingface.co/models/mrm8488/bert-medium-finetuned-squadv2\"\n",
        "\n",
        "def query(payload):\n",
        "    data = json.dumps(payload)\n",
        "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
        "    return json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "data = query(\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"when her nine of the marriage occured?\",\n",
        "            \"context\": \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\"\"\",\n",
        "        }\n",
        "    }\n",
        ")\n",
        "print(data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'score': 0.9679889678955078, 'start': 1286, 'end': 1307, 'answer': 'between 1999 and 2002'}\n",
            "CPU times: user 15 ms, sys: 843 µs, total: 15.8 ms\n",
            "Wall time: 294 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK5ssgdwXzBy",
        "outputId": "ca0e67a1-e29b-4727-fdcc-ed29cab968e8"
      },
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
        "\n",
        "# %%time\n",
        "text = r\"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\"\n",
        "\n",
        "print(len(text.split()))\n",
        "questions = [\n",
        "    \"when her nine of the marriage occured?\",\n",
        "    # \"What does 🤗 Transformers provide?\",\n",
        "    # \"🤗 Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "for question in questions:\n",
        "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    outputs = model(**inputs)\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "    answer_start = torch.argmax(\n",
        "        answer_start_scores\n",
        "    )  # Get the most likely beginning of answer with the argmax of the score\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "Question: when her nine of the marriage occured?\n",
            "Answer: between 1999 and 2002\n",
            "CPU times: user 2.07 s, sys: 119 ms, total: 2.19 s\n",
            "Wall time: 2.81 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2_QgVUlocvc"
      },
      "source": [
        "##Tranformers to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCaePPuQonnz"
      },
      "source": [
        "from time import time\n",
        "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
        "\n",
        "def create_model_for_provider(model_path: str, provider: str) -> InferenceSession: \n",
        "  \n",
        "  assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
        "\n",
        "  # Few properties that might have an impact on performances (provided by MS)\n",
        "  options = SessionOptions()\n",
        "  options.intra_op_num_threads = 1\n",
        "  options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "  # Load the model as a graph and prepare the CPU backend \n",
        "  session = InferenceSession(model_path, options, providers=[provider])\n",
        "  session.disable_fallback()\n",
        "    \n",
        "  return session\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwXgLbDeXbb-",
        "outputId": "b96971af-eaad-4416-c228-e92b561cd28a"
      },
      "source": [
        "tokenizer.save_pretrained(\"qa/\")\n",
        "model.save_pretrained(\"qa/\")\n",
        "from pathlib import Path\n",
        "path = Path(\"onnx/qa.onnx\")\n",
        "!rm -rf onnx/\n",
        "from transformers.convert_graph_to_onnx import convert\n",
        "\n",
        "# Handles all the above steps for you\n",
        "convert(framework=\"pt\",  ## pt for pytorch\n",
        "        model=\"qa\",     ## model path\n",
        "        output=path, \n",
        "        opset=11,\n",
        "        pipeline_name = \"question-answering\") ## pipeline_name is most important when you use this function\n",
        "cpu_model = create_model_for_provider(\"onnx/qa.onnx\", \"CPUExecutionProvider\")\n",
        "# %%time\n",
        "# start_scores, end_scores = cpu_model.run(None, inputs_onnx)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONNX opset version set to: 11\n",
            "Loading pipeline (model: qa, tokenizer: qa)\n",
            "Creating folder onnx\n",
            "Using framework PyTorch: 1.8.1+cu101\n",
            "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_1 with shape: {0: 'batch', 1: 'sequence'}\n",
            "Ensuring inputs are in correct order\n",
            "position_ids is not present in the generated input list.\n",
            "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1790: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sl29um1lBtl",
        "outputId": "1bd38138-b46e-4466-e92e-718f5f5e5d6e"
      },
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "\n",
        "text = r\"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\"\n",
        "\n",
        "print(len(text.split()))\n",
        "questions = [\n",
        "    \"when her nine of the marriage occured?\",\n",
        "    # \"What does 🤗 Transformers provide?\",\n",
        "    # \"🤗 Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
        "inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "inputs_onnx= {\n",
        "    'input_ids' : inputs.input_ids.numpy(),\n",
        "    'attention_mask' : inputs.attention_mask.numpy(), \n",
        "    'token_type_ids' : inputs.token_type_ids.numpy(),\n",
        "}\n",
        "\n",
        "cpu_model = create_model_for_provider(\"onnx/qa.onnx\", \"CPUExecutionProvider\")\n",
        "output=cpu_model.run(None,inputs_onnx)\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "# all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "# print(tokenizer.convert_tokens_to_string(all_tokens[torch.argmax(torch.tensor(start_scores)) : torch.argmax(torch.tensor(end_scores))+1]))\n",
        "answer_start = torch.argmax(\n",
        "        start_scores\n",
        "    )  # Get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "print(f\"Question: {questions[0]}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "Question: when her nine of the marriage occured?\n",
            "Answer: between 1999 and 2002\n",
            "CPU times: user 1.02 s, sys: 538 ms, total: 1.56 s\n",
            "Wall time: 2.15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHMHwkE1lTBq"
      },
      "source": [
        "##optimizations \n",
        "\n",
        "https://medium.com/analytics-vidhya/speedup-pytorch-inference-with-onnx-284d6a47936e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghw43IhYfNOU",
        "outputId": "c22300e7-2bca-4c0b-a26d-ccf0784d1f8e"
      },
      "source": [
        "from onnxruntime_tools import optimizer\n",
        "from onnxruntime_tools.transformers.onnx_model_bert import BertOptimizationOptions\n",
        "\n",
        "# disable embedding layer norm optimization for better model size reduction\n",
        "opt_options = BertOptimizationOptions('bert')\n",
        "opt_options.enable_embed_layer_norm = False\n",
        "\n",
        "opt_model = optimizer.optimize_model(\n",
        "    \"onnx/qa.onnx\",\n",
        "    'bert', \n",
        "    num_heads=12,\n",
        "    hidden_size=768,\n",
        "    optimization_options=opt_options)\n",
        "opt_model.save_model_to_file('onnx/qa.opt.onnx')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: onnxruntime_tools is deprecated. Use onnxruntime or onnxruntime-gpu instead. For more information, see https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/README.md.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n",
            "--num_heads is {self.num_heads}. Detected value is {num_heads}. Using detected value.\n",
            "--hidden_size is {self.hidden_size}. Detected value is {hidden_size}. Using detected value.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJkM9reqrV8h",
        "outputId": "220a42e0-db81-4c84-bfad-5b17334e4584"
      },
      "source": [
        "import os\n",
        "def print_size_of_model(model):\n",
        "    print('Size (MB):', os.path.getsize(model)/(1024*1024))\n",
        "    # os.remove('temp.p')\n",
        "print_size_of_model(\"/content/onnx/qa.onnx\")\n",
        "print_size_of_model(\"/content/qa/pytorch_model.bin\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size (MB): 156.87521266937256\n",
            "Size (MB): 156.88487911224365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0D1TgUbhOJh",
        "outputId": "64b874ec-feed-4fd2-e4ba-fa0a8755eeee"
      },
      "source": [
        "from os import environ\n",
        "from psutil import cpu_count\n",
        "\n",
        "# Constants from the performance optimization available in onnxruntime\n",
        "# It needs to be done before importing onnxruntime\n",
        "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
        "print(str(cpu_count(logical=True)))\n",
        "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RklecbUn62O"
      },
      "source": [
        "## Quantize model\n",
        "https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/quantization/notebooks/bert/Bert-GLUE_OnnxRuntime_quantization.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlRxpzwVsdCS"
      },
      "source": [
        "def quantize_onnx_model(onnx_model_path, quantized_model_path):\n",
        "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "    import onnx\n",
        "    onnx_opt_model = onnx.load(onnx_model_path)\n",
        "    quantize_dynamic(onnx_model_path,\n",
        "                     quantized_model_path,\n",
        "                     weight_type=QuantType.QInt8)\n",
        "\n",
        "    logger.info(f\"quantized model saved to:{quantized_model_path}\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nbuv4m-hPn6",
        "outputId": "0ca798b8-f37d-4f10-c888-265182ff8bee"
      },
      "source": [
        "from transformers.convert_graph_to_onnx import quantize\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "# Transformers allow you to easily convert float32 model to quantized int8 with ONNX Runtime\n",
        "# quantized_model_path = quantize(Path(\"/content/onnx/qa.opt.onnx\"))\n",
        "quantized_model_path = quantize_onnx_model(Path(\"/content/onnx/qa.opt.onnx\"),\"onnx/qa.opt.quant.onnx\")\n",
        "print('ONNX full precision model size (MB):', os.path.getsize(\"onnx/qa.opt.onnx\")/(1024*1024))\n",
        "print('ONNX quantized model size (MB):', os.path.getsize(\"onnx/qa.opt.quant.onnx\")/(1024*1024))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONNX full precision model size (MB): 156.8445987701416\n",
            "ONNX quantized model size (MB): 39.39502429962158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVIG40mDYoVF",
        "outputId": "cfb8fcaa-2a24-4330-a2e8-c540a3f205bf"
      },
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "\n",
        "text = r\"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\"\n",
        "\n",
        "print(len(text.split()))\n",
        "questions = [\n",
        "    \"when her nine of the marriage occured?\",\n",
        "    # \"What does 🤗 Transformers provide?\",\n",
        "    # \"🤗 Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
        "inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "inputs_onnx= {\n",
        "    'input_ids' : inputs.input_ids.numpy(),\n",
        "    'attention_mask' : inputs.attention_mask.numpy(), \n",
        "    'token_type_ids' : inputs.token_type_ids.numpy(),\n",
        "}\n",
        "\n",
        "cpu_model = create_model_for_provider(\"/content/onnx/qa.opt.onnx\", \"CPUExecutionProvider\")\n",
        "output=cpu_model.run(None,inputs_onnx)\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "# all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "# print(tokenizer.convert_tokens_to_string(all_tokens[torch.argmax(torch.tensor(start_scores)) : torch.argmax(torch.tensor(end_scores))+1]))\n",
        "answer_start = torch.argmax(\n",
        "        start_scores\n",
        "    )  # Get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "print(f\"Question: {questions[0]}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "Question: when her nine of the marriage occured?\n",
            "Answer: between 1999 and 2002\n",
            "CPU times: user 810 ms, sys: 63.3 ms, total: 873 ms\n",
            "Wall time: 1.38 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJAF9EqWPGC3",
        "outputId": "4c3a2f8e-432e-4261-89e0-6a2b06847f4c"
      },
      "source": [
        "%%time\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "\n",
        "text = r\"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\"\n",
        "\n",
        "print(len(text.split()))\n",
        "questions = [\n",
        "    \"when her nine of the marriage occured?\",\n",
        "    # \"What does 🤗 Transformers provide?\",\n",
        "    # \"🤗 Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
        "inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "inputs_onnx= {\n",
        "    'input_ids' : inputs.input_ids.numpy(),\n",
        "    'attention_mask' : inputs.attention_mask.numpy(), \n",
        "    'token_type_ids' : inputs.token_type_ids.numpy(),\n",
        "}\n",
        "\n",
        "cpu_model = create_model_for_provider(\"/content/onnx/qa.opt.quant.onnx\", \"CPUExecutionProvider\")\n",
        "output=cpu_model.run(None,inputs_onnx)\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "# all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "# print(tokenizer.convert_tokens_to_string(all_tokens[torch.argmax(torch.tensor(start_scores)) : torch.argmax(torch.tensor(end_scores))+1]))\n",
        "answer_start = torch.argmax(\n",
        "        start_scores\n",
        "    )  # Get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "print(f\"Question: {questions[0]}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "Question: when her nine of the marriage occured?\n",
            "Answer: between 1999 and 2002\n",
            "CPU times: user 596 ms, sys: 16.9 ms, total: 613 ms\n",
            "Wall time: 983 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1TbmgwuyU7q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}